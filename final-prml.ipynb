{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport sklearn\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import normalize\nfrom collections import defaultdict\nimport itertools\nfrom datetime import datetime\nimport geopy\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#bikers = pd.read_csv(\"/kaggle/input/prml-data-contest-nov-2020/bikers.csv\")\nbikers_network = pd.read_csv(\"/kaggle/input/prml-data-contest-nov-2020/bikers_network.csv\")\ntour_convoy = pd.read_csv(\"/kaggle/input/prml-data-contest-nov-2020/tour_convoy.csv\")\n#tours = pd.read_csv(\"/kaggle/input/prml-data-contest-nov-2020/tours.csv\")\ntrain = pd.read_csv(\"/kaggle/input/prml-data-contest-nov-2020/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/prml-data-contest-nov-2020/test.csv\")\nlocations = pd.read_csv(\"../input/prml2020-cs57/locations.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Merge biker and tour in train and test to extract unique values\ndata = pd.concat([train[['biker_id','tour_id']],test[['biker_id','tour_id']]],axis=0)\n\nuniquebikers=set(data['biker_id'])\nuniquetours=set(data['tour_id'])\n\n#Build biker-tours and tour-bikers collection\ndata=data.reset_index(drop=True)\ntoursForbiker=defaultdict(set)\nbikersFortour=defaultdict(set)\nfor i in range(len(data)):\n    toursForbiker[data['biker_id'][i]].add(data['tour_id'][i])\n    bikersFortour[data['tour_id'][i]].add(data['biker_id'][i])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import bikers data\ndf_bikers=pd.read_csv(r'/kaggle/input/prml-data-contest-nov-2020/bikers.csv')\n\n#print(df_bikers.info())\n\n#biker matrix preprocessing\nle = LabelEncoder()\n\ndf_bikers['gender']=df_bikers['gender'].fillna('NaN')\ndf_bikers['gender']=le.fit_transform(df_bikers['gender'])\n\ndf_bikers['location_id']=le.fit_transform(df_bikers['location_id'])\ndf_bikers['language_id']=le.fit_transform(df_bikers['language_id'])\n\ndef bornInInt(bornIn):\n    try:\n        return np.nan if bornIn=='None' else int(bornIn)\n    except:\n        return np.nan\ndf_bikers['bornIn']=df_bikers['bornIn'].map(bornInInt)\n\ndef timezoneInt(timezone):\n    try:\n        return int(timezone)\n    except:\n        return np.nan\ndf_bikers['time_zone']=df_bikers['time_zone'].map(timezoneInt)\n\n#print(df_bikers.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tours = pd.read_csv(r'/kaggle/input/prml-data-contest-nov-2020/tours.csv')\n\n# we only consider the tours present in train/test files\ndf_tours1 = df_tours[df_tours.tour_id.isin(uniquetours)]\ndf_tours1 = df_tours1.reset_index(drop = True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cluster_df = df_tours1[df_tours1.columns[9:109]]\nword_counts = cluster_df\n\n#clustering and labelling of tours based on description\nfrom sklearn.cluster import KMeans\n\nlabel = KMeans(n_clusters = 30, max_iter = 4000, random_state = 0).fit_predict(cluster_df)\n\ndft = pd.DataFrame(label, columns = ['labels'])\ndf_tours2 = pd.concat([df_tours1, dft], axis = 1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# only considering tours in train/test\ntour_convoy1 = tour_convoy[tour_convoy.tour_id.isin(uniquetours)].reset_index(drop=True)\n\n# numner of people yes/no/maybe/invited for a tour\nntours = len(uniquetours)\ntourPopY = np.zeros(ntours)\ntourPopN = np.zeros(ntours)\ntourPopM = np.zeros(ntours)\ntourPopI = np.zeros(ntours)\n\n# set of bikers for each- going/not going etc.\ngoingTour = defaultdict(set)\nngoingTour = defaultdict(set)\nmaybeTour = defaultdict(set)\ninviteTour = defaultdict(set)\n\n#tours a biker is going/not going/maybe/invited\nbikerGoing = defaultdict(set)\nbikerNGoing = defaultdict(set)\nbikerMaybe = defaultdict(set)\nbikerInvite = defaultdict(set)\n\n# computing tour popularity and adding to features\nfor i in range(ntours):\n    tourId=tour_convoy1['tour_id'][i]\n    goingT = str(tour_convoy1['going'][i]).split(' ')\n    notgoingT = str(tour_convoy1['not_going'][i]).split(' ')\n    maybeT = str(tour_convoy1['maybe'][i]).split(' ')\n    inviteT = str(tour_convoy1['invited'][i]).split(' ')\n    goingTour[tourId] = set(goingT)\n    ngoingTour[tourId] = set(notgoingT)\n    maybeTour[tourId] = set(maybeT)\n    inviteTour[tourId] = set(inviteT)\n    if str(tour_convoy1['going'][i])=='nan':\n        len_y=0\n    else:\n        len_y=len(tour_convoy1['going'][i].split(' '))\n    if str(tour_convoy1['not_going'][i])=='nan':\n        len_n=0\n    else:\n        len_n=len(tour_convoy1['not_going'][i].split(' '))\n    if str(tour_convoy1['maybe'][i])=='nan':\n        len_m=0\n    else:\n        len_m=len(tour_convoy1['maybe'][i].split(' '))\n    if str(tour_convoy1['invited'][i])=='nan':\n        len_i=0\n    else:\n        len_i=len(tour_convoy1['invited'][i].split(' '))\n    tourPopY[i] = len_y\n    tourPopN[i] = len_n\n    tourPopM[i] = len_m\n    tourPopI[i] = len_i\n    for bikid in goingT:\n        bikerGoing[bikid].add(tourId)\n    for bikid in notgoingT:\n        bikerNGoing[bikid].add(tourId)\n    for bikid in maybeT:\n        bikerMaybe[bikid].add(tourId)\n    for bikid in inviteT:\n        bikerInvite[bikid].add(tourId)\n\ntour_convoy1['tourPopY'] = pd.Series(tourPopY)\ntour_convoy1['tourPopN'] = pd.Series(tourPopN)\ntour_convoy1['tourPopM'] = pd.Series(tourPopM)\ntour_convoy1['tourPopI'] = pd.Series(tourPopI)\n\ndf_tours3 = df_tours2.merge(tour_convoy1[['tour_id', 'tourPopY', 'tourPopN', 'tourPopM', 'tourPopI']], on = 'tour_id')\ndf_tours3.rename(columns = {'biker_id': 'organiser'}, inplace = True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#analysing bikers_network features and adding number of friends, and set of a bikers friends\nfriends = defaultdict(set)\n\nbiker_net1 = bikers_network[bikers_network.biker_id.isin(uniquebikers)].reset_index(drop=True)\nnumfriends = np.zeros(len(biker_net1))\n\nfor i in range(len(biker_net1)):\n    bikerId = biker_net1['biker_id'][i]\n    friend_list = biker_net1['friends'][i].split(' ')\n    friends[bikerId] = set(friend_list)\n    numfriends[i] = len(friend_list)\n\nnf = pd.DataFrame(numfriends, columns = ['num_friends'])\nbikernet = pd.concat([biker_net1, nf], axis = 1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Building the feature matrix for train/test files\n\ny_train = train[['like']]\nx_train = train[['biker_id', 'tour_id', 'invited', 'timestamp']]\nx_test = test[['biker_id', 'tour_id', 'invited', 'timestamp']]\nx_all = pd.concat([x_train.assign(is_train=1),x_test.assign(is_train=0)],axis=0).reset_index(drop = True)\n\n# label corresponding to cluster number, tour similarity\ndef addlabel(x):  \n    labeller = df_tours3[['tour_id', 'labels']]\n    return pd.merge(x, labeller, on = 'tour_id', how = 'left')\n\n# tour popularity features - number going/ not going/ maybe/ invited\ndef addtourPop(x):\n    tourpops = df_tours3[['tour_id', 'tourPopY', 'tourPopN', 'tourPopM', 'tourPopI']]\n    return pd.merge(x, tourpops, on = 'tour_id', how = 'left')\n\n# number of friends of a biker\ndef addnum_friends(x):\n    frens = bikernet[['biker_id', 'num_friends']]\n    return pd.merge(x, frens, on = 'biker_id', how = 'left')\n\n# basic information about biker\ndef addbikerinfo(x):\n    biker_info = df_bikers[['biker_id', 'language_id', 'location_id', 'gender', 'member_since', 'area','bornIn', 'time_zone']]\n    return pd.merge(x, biker_info, on = 'biker_id', how = 'left')\n\n# age of biker\ndef addage(x):\n    age = []\n    for i in range(len(x)):\n        if np.isnan(x['bornIn'][i]):\n            age.append(np.nan)\n        else:\n            yearb = x['bornIn'][i]\n            age.append(2013 - yearb)\n    x['age'] = pd.Series(age)\n    return x\n\n#info about tours\ndef addtourinfo(x):\n    tour_info = df_tours3[['tour_id', 'organiser', 'tour_date', 'city', 'state', 'country', 'latitude', 'longitude']]\n    tour_info.rename(columns = {'latitude': 'tour_lat', 'longitude': 'tour_lng'}, inplace = True)\n    return pd.merge(x, tour_info, on = 'tour_id', how = 'left')\n\n# number of tours shown to a biker in train/test file\ndef addtourForbiker(x):\n    ntoursbiker = []\n    for i in range(len(x)):\n        bikid = x['biker_id'][i]\n        ntoursbiker.append(len(toursForbiker[bikid]))\n    x['ntoursShown'] = pd.Series(ntoursbiker)\n    return x\n\n# number of tours a biker is going/not going/ maybe/ invited\ndef addbikerTours(x):\n    bikGoing, bikNGoing, bikMaybe, bikInvite = [], [], [], []\n    for i in range(len(x)):\n        bikGoing.append(len(bikerGoing[x['biker_id'][i]]))\n        bikNGoing.append(len(bikerNGoing[x['biker_id'][i]]))\n        bikMaybe.append(len(bikerMaybe[x['biker_id'][i]]))\n        bikInvite.append(len(bikerInvite[x['biker_id'][i]]))\n    x['bik_G'] = pd.Series(bikGoing)\n    x['bik_NG'] = pd.Series(bikNGoing)\n    x['bik_M'] = pd.Series(bikMaybe)\n    x['bik_I'] = pd.Series(bikInvite)\n    return x\n\n# number of days between (i) tour_date and member_since\n                        #(ii) timestamp and member_since\n                        #(iii) tour_date and timestamp (time to tour)\ndef adddateDiffs(x):\n    diff1, diff2, diff3 = [], [], []\n    for i in range(len(x)):\n        t1 = datetime.strptime(x['member_since'][i], \"%d-%m-%Y\")\n        t2 = datetime.strptime(x['tour_date'][i], \"%d-%m-%Y\")\n        t3 = datetime.strptime(x['timestamp'][i], \"%d-%m-%Y %H:%M:%S\")\n        diff1.append((t2-t1).days + 1/86400 * (t2-t1).seconds)\n        diff2.append((t3-t1).days + 1/86400 * (t3-t1).seconds)\n        diff3.append((t2-t3).days + 1/86400 * (t2-t3).seconds)\n    x['diff1'] = pd.Series(diff1)\n    x['diff2'] = pd.Series(diff2)\n    x['diff3'] = pd.Series(diff3)\n    return x\n\n# is organiser a friend\ndef addorganiserFren(x):\n    list1 = []\n    for i in range(len(x)):\n        organiserId = x['organiser'][i]\n        bikId = x['biker_id'][i]\n        if organiserId in friends[bikId]:\n            list1.append(1)\n        else:\n            list1.append(0)\n    x['isOrganiserFrnd'] = pd.Series(list1)\n    return x\n\n# number of friends of biker going/ not going/ maybe/ invited\ndef addfriendsInfl(x):\n    freninfl1 = []\n    freninfl2 = []\n    freninfl3 = []\n    freninfl4 = []\n    for i in range(len(x)):\n        bikid = x['biker_id'][i]\n        tourid = x['tour_id'][i]\n        t1 = len(friends[bikid].intersection(goingTour[tourid]))\n        t2 = len(friends[bikid].intersection(ngoingTour[tourid]))\n        t3 = len(friends[bikid].intersection(maybeTour[tourid]))\n        t4 = len(friends[bikid].intersection(inviteTour[tourid]))\n        t5 = len(friends[bikid])\n        freninfl1.append(t1)\n        freninfl2.append(t2)\n        freninfl3.append(t3)\n        freninfl4.append(t4)\n    x['friendsInfl1'] = pd.Series(freninfl1)\n    x['friendsInfl2'] = pd.Series(freninfl2)\n    x['friendsInfl3'] = pd.Series(freninfl3)\n    x['friendsInfl4'] = pd.Series(freninfl4)\n    return x\n\n# biker location from locations.csv\ndef addbikLocation(x):\n    biklocation = locations[['biker_id', 'latitude', 'longitude']]\n    biklocation.rename(columns = {'latitude': 'bik_lat', 'longitude': 'bik_lng'}, inplace = True)\n    return pd.merge(x, biklocation, on = 'biker_id', how = 'left')\n \n    \n# Importing the geodesic module from the library to get tour-biker distance\nfrom geopy.distance import geodesic as geodis\n\ndef adddistance(x):\n    dist = []\n    for i in range(len(x)):\n        if np.isnan(x['bik_lat'][i]):\n            dist.append(np.nan)\n        elif np.isnan(x['tour_lat'][i]):\n            dist.append(np.nan)\n        else:\n            bikloc = (x['bik_lat'][i], x['bik_lng'][i])\n            tourloc = (x['tour_lat'][i], x['tour_lng'][i])\n            dist.append(geodis(bikloc, tourloc).km)\n    x['distance'] = pd.Series(dist)\n    return x\n            \n\nx_all = addlabel(x_all)\nx_all = addtourPop(x_all)\nx_all = addnum_friends(x_all)\nx_all = addbikerinfo(x_all)\nx_all = addage(x_all)\nx_all = addtourinfo(x_all)\nx_all = addbikerTours(x_all)\nx_all = addtourForbiker(x_all)\nx_all = adddateDiffs(x_all)\nx_all = addorganiserFren(x_all)\nx_all = addfriendsInfl(x_all)\nx_all = addbikLocation(x_all)\nx_all = adddistance(x_all)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = ['biker_id', 'tour_id', 'invited', 'labels', 'tourPopY', 'tourPopN', 'tourPopM', 'tourPopI',\n        'num_friends', 'language_id', 'location_id', 'gender','bornIn', 'age',\n        'tour_lat', 'tour_lng', 'ntoursShown', 'diff1', 'diff2', 'diff3', 'isOrganiserFrnd', \n        'bik_G', 'bik_NG', 'bik_M', 'bik_I',\n        'friendsInfl1', 'friendsInfl2', 'friendsInfl3', 'friendsInfl4', 'bik_lat', 'bik_lng', 'distance'\n        ]\n\nx_train = x_all[x_all['is_train']==1][cols]\nx_test = x_all[x_all['is_train']==0][cols]\n\n#Sanity check\n#print(x_train.info())\n#print(y_train.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\n\nocols = ['invited', 'labels', 'tourPopY', 'tourPopN', 'tourPopM', \n         'tourPopI', 'num_friends','language_id', 'location_id','gender', \n         'bornIn', 'tour_lat', 'tour_lng','ntoursShown', 'diff1', 'diff2', 'diff3','isOrganiserFrnd', \n         'friendsInfl1', 'friendsInfl2', 'friendsInfl3', 'friendsInfl4',\n         #'bik_G', 'bik_NG', 'bik_M', 'bik_I',\n         'bik_lat' , 'bik_lng', 'distance',\n        ]  #25\n\nX = x_train[ocols].to_numpy()\ny = y_train.to_numpy().ravel()\n\n#Split training data\nfrom sklearn.model_selection import train_test_split\nXtrain,Xtest,ytrain,ytest = train_test_split(X,y,test_size=0.3,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import seaborn as sns\n#import matplotlib.pyplot as plt\n#corrf = pd.DataFrame(X).corr()\n#f, ax = plt.subplots(figsize=(12, 9))\n#sns.heatmap(corrf, vmax=.8, square=True);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# parameters obtained from hyperparameter tuning\n#print(opt_params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Sanity check on classifier\nimport lightgbm as lgb\n\nlgbmc1 = lgb.LGBMClassifier(boosting_type='gbdt',  num_leaves = 58, \n                         max_depth=12, learning_rate=0.09,reg_lambda = 1.0,\n                         n_estimators=150, feature_fraction = 0.6740, seed=0\n                         )\nclf_lg = lgbmc1.fit(Xtrain,ytrain)\n\n#print(clf_lg.score(Xtrain, ytrain))\n#print(clf_lg.score(Xtest, ytest))\n#print(clf_lg)\n\n#lgb.plot_importance(clf_lg)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\n\n# training the classifier on all of the data\ndef trainfun(clf):\n    trainDf = x_train\n    X = pd.DataFrame(trainDf, index=None, columns=ocols)\n    y = np.array(y_train).ravel()\n    \n    clf.fit(X, y)\n    return clf\n \n# k-fold validation\ndef validatefun(clf):   \n    trainDf = x_train[ocols]\n    X = np.matrix(pd.DataFrame(trainDf, index=None, columns=ocols))\n    y = np.array(y_train).ravel()\n     \n    nrows = len(trainDf)\n    kfold = KFold(n_splits=10,shuffle=False)\n    avgAccuracy = 0\n    run = 0\n    for train, test in kfold.split(X, y):\n        Xtrain, Xtest, ytrain, ytest = X[train], X[test], y[train], y[test]\n        \n        clf.fit(Xtrain, ytrain)\n        accuracy = 0\n        ntest = len(ytest)\n        for i in range(0, ntest):\n            yt = clf.predict(Xtest[i, :])\n            if yt == ytest[i]:\n                accuracy += 1\n                 \n        accuracy = accuracy / ntest\n        run += 1\n        print('accuracy(run %d) : %f' % (run, accuracy) )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating the submission file with the trained classifier\ndef testfun(clf, filename):\n    testDf = np.matrix(pd.DataFrame(x_test, index=None, columns=ocols))\n     \n    nrows = len(testDf)\n    donebik = []\n    tlist = []\n    for i in range(nrows):\n        bikid = test['biker_id'][i]\n        if bikid in donebik:\n            continue\n        list1 = []\n        for j in range(i, nrows):\n            if test['biker_id'][j] == bikid :\n                tourid = test['tour_id'][j]\n                pred = clf.predict_proba(testDf[j, :])\n                list1.append([tourid, pred[0][0]])\n        list1.sort(key = lambda x: x[1])\n        donebik.append(bikid)\n        tids = np.array(list1)\n        #print(tids[0, -1])\n        tids = \" \".join(tids[:,0])\n        tlist.append(tids)\n        \n    sample_submission =pd.DataFrame(columns=[\"biker_id\",\"tour_id\"])\n    sample_submission[\"biker_id\"] = donebik\n    sample_submission[\"tour_id\"] = tlist\n    sample_submission.to_csv(filename,index=False)\n    #print(sample_submission.shape)\n    #print(sample_submission.head(4))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf1 = lgbmc1\ntrainfun(clf1)\n#validatefun(clf1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testfun(clf1, \"CS18B057_CS18B046_1.csv\")\n# 1st submission file made","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = ['biker_id', 'tour_id', 'invited', 'labels', 'tourPopY', 'tourPopN', 'tourPopM', 'tourPopI',\n        'num_friends', 'language_id', 'location_id', 'gender','bornIn', 'age',\n        'tour_lat', 'tour_lng', 'ntoursShown', 'diff1', 'diff2', 'diff3', 'isOrganiserFrnd', \n        'bik_G', 'bik_NG', 'bik_M', 'bik_I',\n        'friendsInfl1', 'friendsInfl2', 'friendsInfl3', 'friendsInfl4', 'bik_lat', 'bik_lng', 'distance', \n        ]\n\nx_train = x_all[x_all['is_train']==1][cols]\nx_test = x_all[x_all['is_train']==0][cols]\n#print(x_train.info())\n#print(y_train.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\n\nocols = ['invited', 'labels', 'tourPopY', 'tourPopN', 'tourPopM', \n         'tourPopI', 'num_friends','language_id', 'location_id','gender', \n         'bornIn', 'tour_lat', 'tour_lng','ntoursShown', 'diff1', 'diff2', 'diff3','isOrganiserFrnd', \n         'friendsInfl1', 'friendsInfl2', 'friendsInfl3', 'friendsInfl4',\n         'bik_G', 'bik_NG', 'bik_M', 'bik_I', 'bik_lat' , 'bik_lng', 'distance',\n        ]  \n\nX = x_train[ocols].to_numpy()\ny = y_train.to_numpy().ravel()\n\n#Split training data\nfrom sklearn.model_selection import train_test_split\nXtrain,Xtest,ytrain,ytest = train_test_split(X,y,test_size=0.3,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(opt_params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import lightgbm as lgb\n\nlgbmc2 = lgb.LGBMClassifier(boosting_type='gbdt',  num_leaves = 43, \n                         max_depth=11, learning_rate=0.074,reg_lambda = 0.457,\n                         n_estimators=100, feature_fraction = 0.844, seed=0 \n                         )\nclf_lg = lgbmc2.fit(Xtrain,ytrain)\n\n\n#print(clf_lg.score(Xtrain, ytrain))\n#print(clf_lg.score(Xtest, ytest))\n#print(clf_lg)\n\n#lgb.plot_importance(clf_lg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf2 = lgbmc2\ntrainfun(clf2)\n#validatefun(clf2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testfun(clf2, \"CS18B057_CS18B046_2.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nfrom bayes_opt import BayesianOptimization\nfrom skopt  import BayesSearchCV \nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\nimport time\nimport sys\n\n#metrics \nfrom sklearn.metrics import roc_auc_score, roc_curve\nimport shap\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\ndef bayes_parameter_opt_lgb(X, y, init_round=15, opt_round=25, n_folds=3, random_seed=6,n_estimators=200, output_process=False):\n    # prepare data\n    train_data = lgb.Dataset(data=X, label=y, free_raw_data=False)\n    # parameters\n    def lgb_eval(learning_rate,num_leaves, feature_fraction, #bagging_fraction, \n                 max_depth, reg_lambda):#, max_bin, min_data_in_leaf,min_sum_hessian_in_leaf,subsample):\n        params = {'objective':'binary', 'metric':'auc'}\n        params['learning_rate'] = max(min(learning_rate, 1), 0)\n        params['num_leaves'] = int(round(num_leaves))\n        params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n        #params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n        params['max_depth'] = int(round(max_depth))\n        #params['max_bin'] = int(round(max_depth))\n        #params['min_data_in_leaf'] = int(round(min_data_in_leaf))\n        #params['min_sum_hessian_in_leaf'] = min_sum_hessian_in_leaf\n        #params['subsample'] = max(min(subsample, 1), 0)\n        params['reg_lambda'] = max(min(feature_fraction, 10), 0)\n        \n        cv_result = lgb.cv(params, train_data, nfold=n_folds, seed=random_seed, stratified=True, verbose_eval =200, metrics=['auc'])\n        return max(cv_result['auc-mean'])\n     \n    lgbBO = BayesianOptimization(lgb_eval, {'learning_rate': (0.01, 0.09),\n                                            'num_leaves': (16, 64),\n                                            'feature_fraction': (0.3, 0.9),\n                                            #'bagging_fraction': (0.8, 1),\n                                            'max_depth': (5, 12),\n                                            #'max_bin':(10,90),\n                                            #'min_data_in_leaf': (10, 80),\n                                            #'min_sum_hessian_in_leaf':(0,100),\n                                           #'subsample': (0.01, 1.0)},\n                                            'reg_lambda': (0.1, 1.0),\n                                            \n                                           },random_state=200)\n\n    \n    #n_iter: How many steps of bayesian optimization you want to perform. The more steps the more likely to find a good maximum you are.\n    #init_points: How many steps of random exploration you want to perform. Random exploration can help by diversifying the exploration space.\n    \n    lgbBO.maximize(init_points=init_round, n_iter=opt_round)\n    \n    model_auc=[]\n    for model in range(len( lgbBO.res)):\n        model_auc.append(lgbBO.res[model]['target'])\n    \n    # return best parameters\n    return lgbBO.res[pd.Series(model_auc).idxmax()]['target'],lgbBO.res[pd.Series(model_auc).idxmax()]['params']\n\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#opt_params = bayes_parameter_opt_lgb(X, y, init_round=15, opt_round=25, n_folds=10, random_seed=6,n_estimators=150)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(opt_params)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}